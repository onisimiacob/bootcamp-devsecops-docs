{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DevSecOps Bootcamp Documentation","text":"<p>These are  Onisim Iacob personal notes for the  Techworld-With-Nana DevSecOps Bootcamp written in with  Mkdocs-Materials and deployed on  Github Pages as a free static site.</p>"},{"location":"#no-ai-usage","title":"No AI usage","text":""},{"location":"#i-wanted-to-ensure-every-single-word-comes-from-my-mouth-i-do-however-use-ai-at-work-to-increase-my-productivity-but-not-for-this-kind-of-courses","title":"I wanted to ensure every single word comes from my mouth. I do however use AI at work to increase my productivity, but not for this kind of courses.","text":"<p> Check Documented Modules</p>"},{"location":"#to-ensure-copyright-policy","title":"To ensure copyright policy","text":"<ul> <li>I will not use any screenshot of the course itself, nor any PDF from TechWorld with Nana's DevSecOps Bootcamp .</li> </ul>"},{"location":"#objective","title":"Objective","text":"<ul> <li> <p>After completing this Bootcamp, hand this static site to validate my new knewledge, in a modern way.</p> </li> <li> <p>Have the evidence and hands-on resolution of the exercises.</p> </li> <li> <p>I want to keep all this knewledge as a static site for documentation to check it any time I need.</p> </li> <li> <p>Static sites like this, on any real project, can give to the DevOps Engineer a huge value.</p> </li> </ul>"},{"location":"pages/1-security-essentials/","title":"\ud83d\udee1\ufe0f Security Essentials","text":"<ul> <li> <p>In this first module I learned that we need to secure:</p> <ul> <li>Customer data.</li> <li>Company data.</li> <li>Internal applications.</li> <li>User applications.</li> </ul> </li> </ul>","tags":["Attacks","Essentials","OWASP","Top 10"]},{"location":"pages/1-security-essentials/#types-of-security-attacks","title":"Types of Security Attacks","text":"<ul> <li> <p>Phising attack: A human is the target, not a system</p> <ul> <li>User will receive an email, or any other communication in order to get tricked and to give the attacker some sensitive information.</li> </ul> </li> <li> <p>XSS - Cross Site Scripting</p> <ul> <li>Runs malicious code or scripts from malicious sources. When other users get connected, server serves the script which is executed on browser.</li> </ul> </li> <li> <p>CSRF - Client Side Request Forgery</p> <ul> <li>This can steal session information and it happens on the user side, which allows the attacker to pretend be another user.</li> </ul> </li> <li> <p>SSRF - Server Side Request Forgery</p> <ul> <li>This is executed on server which is more complicated, but often, much more dangerous as it can affect all users and can reach other resources, such as database or backend.</li> </ul> </li> <li> <p>SQL Injection</p> <ul> <li>Allows users to inject malicious by exploits on libraries or more typically through unsanatized web applications, modifying the database.</li> </ul> </li> <li> <p>Libraries</p> <ul> <li>They are thirdparty code, so they also have exploits or CVEs (Common Vulerability Exposures), to be identified and updated to stay protected.</li> </ul> </li> <li> <p>Brute Force</p> <ul> <li>Some systems may allow very weak passwords, or does not have MFA (Multi-Factor Authentication) or more specifically, the lack of a ratelimit at API level to avoid brute force.</li> </ul> </li> <li> <p>DoS </p> <ul> <li>Here the lack of any ratelimit may be an issue as it can stress the server. It can be the frontend due to millions of calls, or backend if backend URL is reachable. In worse case scenarios, el Backend is open, attacker can even reach the database blocking new connections and denialing the service from the lowest layer (DB), not having any real Frontend traffic.</li> </ul> </li> <li> <p>Security Principal</p> <ul> <li>We have to secure every possible entrypoint.</li> </ul> </li> </ul>","tags":["Attacks","Essentials","OWASP","Top 10"]},{"location":"pages/1-security-essentials/#owasp-and-owasp-top-10","title":"OWASP and OWASP Top 10","text":"<ol> <li>Broken Control Access:<ul> <li>Users may run actions that shoud not be allowed to (violation of least priviledge principal).</li> </ul> </li> <li>Cryptographic Failures:<ul> <li>Hardcoded data, weak or lack of encryption of information, insecure protocols.</li> </ul> </li> <li>Injection<ul> <li>Allows to inject code such as JavaScript, SQL, NoSQL, OS commands.</li> </ul> </li> <li>Insecure Design<ul> <li>\"Leave it like this, we will fix it later\" and later never comes. Very typical situation on day to day projects...</li> </ul> </li> <li>Security Misconfiguration<ul> <li>Open ports, default passwords, infrastructure default values (public). It applies at every level; newwork, storage, application.</li> </ul> </li> <li>Vulnerable and Outdated Components<ul> <li>Everything is code, so if you fix you code, you also need to apply new versions of libraries.</li> </ul> </li> <li>Indentification and Authentication Failures<ul> <li>Errors at properly identify and authenticate users. Weak user confirmation, passwords, lack of mfa, sessions not invalidated.</li> </ul> </li> <li>Software and Data Integration Failures<ul> <li>Using libraries and plugins from unknown sources with weak digital signature.</li> </ul> </li> <li>Security Logging and Monitoring Failures<ul> <li>Detect breaches and notify attach attempts.</li> </ul> </li> <li>Serverside Request Forgery (SSRF)<ul> <li>Malicious code executing from inside the server itself due to a vulnerability on both infrastructure or application.</li> </ul> </li> </ol>","tags":["Attacks","Essentials","OWASP","Top 10"]},{"location":"pages/10-iac-and-gitops-for-devsecops/","title":"\ud83d\udc68\u200d\ud83d\udcbb IaC and GitOps for DevSecOps","text":""},{"location":"pages/10-iac-and-gitops-for-devsecops/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/11.logging-and-monitoring-for-security/","title":"\ud83d\udcca Logging &amp; Monitoring for Security","text":""},{"location":"pages/11.logging-and-monitoring-for-security/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/12-introduction-to-kubernetes-security/","title":"\u2638\ufe0f Introduction to Kubernetes Security","text":""},{"location":"pages/12-introduction-to-kubernetes-security/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/13-kubernetes-access-management-with-aws-eks/","title":"\ud83d\udd13 Kubernetes Access Management with AWS EKS","text":""},{"location":"pages/13-kubernetes-access-management-with-aws-eks/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/14-secure-iac-pipeline-for-eks-provisioning/","title":"\u2705 Secure IaC Pipeline for EKS provisioning","text":""},{"location":"pages/14-secure-iac-pipeline-for-eks-provisioning/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/15-bootraping-clusters-with-eks-blueprints/","title":"\u2728 Bootstrapping clusters with EKS Blueprints","text":""},{"location":"pages/15-bootraping-clusters-with-eks-blueprints/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/16-application-release-pipeline-with-argocd/","title":"\ud83d\udc19 Application Release Pipeline with ArgoCD","text":""},{"location":"pages/16-application-release-pipeline-with-argocd/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/17-policy-as-code-with-open-policy-agent/","title":"\ud83d\udcd1 Policy as Code with Open Policy Agent","text":""},{"location":"pages/17-policy-as-code-with-open-policy-agent/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/18-secrets-management-in-kubernetes/","title":"\ud83e\udd2b Secrets Management in Kubernetes","text":""},{"location":"pages/18-secrets-management-in-kubernetes/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/19-service-mesh-with-istio/","title":"\ud83d\udd78\ufe0f Service Mesh with Istio","text":""},{"location":"pages/19-service-mesh-with-istio/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/2-introduction-to-devsecops/","title":"\ud83c\udd95 Introduction to DevSecOps","text":"<p>Best security practices are automated and go straight inside the DevOps workflow.</p> <p></p>","tags":["DevSecOps","Skills","Comparison"]},{"location":"pages/2-introduction-to-devsecops/#devsecops-engineer-vs-security-engineer","title":"DevSecOps Engineer vs Security Engineer","text":"<ul> <li> <p>Security Engineer: Focuses on securing systems, networks and infrastructure.</p> </li> <li> <p>DevSecOps Engineer: Integrates security on the entire DevOps, is the connection between Dev, Ops and Security team. It also helps Devs and Security Engineers to discover and fix issues.</p> </li> </ul>","tags":["DevSecOps","Skills","Comparison"]},{"location":"pages/2-introduction-to-devsecops/#skills","title":"Skills","text":"<ul> <li>Bridge between teams.</li> <li>Creates processes to help ensure security.</li> <li>Teaches and shares knewledge.</li> </ul>","tags":["DevSecOps","Skills","Comparison"]},{"location":"pages/20-compliance-as-code/","title":"\ud83e\udd1d Compliance as Code","text":""},{"location":"pages/20-compliance-as-code/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/21-how-to-introduce-devsecops-in-organizations/","title":"\ud83d\udcbc How to Introduce DevSecOps In Organizations","text":""},{"location":"pages/21-how-to-introduce-devsecops-in-organizations/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/22-devsecops-certification/","title":"\ud83c\udf93 DevSecOps Certification","text":""},{"location":"pages/22-devsecops-certification/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/3-application-vulnerability-scanning/","title":"\ud83d\udd0e Application Vulnerability Scanning","text":"","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#exercise-build-a-continuous-integration-pipeline","title":"EXERCISE: Build a Continuous Integration Pipeline","text":"<ul> <li>Create a Gitlab account  </li> <li>Fork the repository: https://gitlab.com/onisimiacob/juice-shop</li> </ul> <p>Note</p> <ul> <li>Starting Code: https://gitlab.com/twn-devsecops-bootcamp/latest/juice-shop/-/tree/feature/starting-code</li> <li>CI Pipeline: https://gitlab.com/twn-devsecops-bootcamp/latest/juice-shop/-/tree/feature/03.01-build-ci</li> </ul> <ul> <li>Add SSH credentials to the Gitlab Account following https://docs.gitlab.com/user/ssh/</li> <li>Clone repository locally.</li> <li>Create a DockerHub account: https://app.docker.com/signup</li> </ul> <p>For this exercise, go to the repository setComparisontings and set <code>juice-shop &gt; CI/CD Settings</code> and set <code>CI/CD configuration file</code> to <code>.gitlab/.gitlab-ci.yml</code>, otherwise the pipeline will try to be created on root folder.</p>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#insecure-pipeline-avoid-saving-passwords-as-variables","title":"INSECURE PIPELINE! Avoid saving passwords as variables!","text":"<pre><code>variables:\n  IMAGE_NAME: onisimiacob/demo-app\n  IMAGE_VERSION: juice-shop-1.0\n\nstages:\n  - cache\n  - test\n  - build\n\n# Improove build times with a cache task that saves the dependencies as an artifact\ncreate_cache:\n  image: node:18-bullseye\n  stage: cache\n  script:\n    - yarn install --ignore-engines \n  cache:\n    key:\n      files:\n        - yarn.lock\n    paths:\n      - node_modules\n      - yarn.lock\n      - .yarn\n    policy: pull-push\n\n# Test using the cache to speedup testing\nyarn_test:\n  image: node:18-bullseye\n  stage: test\n  script:\n    - yarn install --ignore-engines # fix The engine \"node\" is incompatible with this module. Expected version \"20 || &gt;=22\". Got \"18.20.8\"\n    - yarn test\n  cache:\n    key:\n      files:\n        - yarn.lock\n    paths:\n      - node_modules\n      - yarn.lock\n      - .yarn\n    policy: pull\n\n# Build the docker image\nbuild_image:\n  stage: build\n  image: docker:24\n  services:\n    - docker:24-dind\n  variables:\n    DOCKER_USER: onisimiacob\n    DOCKER_PASS: 1234567890!\n  before_script:\n    - echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin\n  script:\n    - docker build -t $IMAGE_NAME:$IMAGE_VERSION .\n    - docker push $IMAGE_NAME:$IMAGE_VERSION\n</code></pre>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#secure-pipeline","title":"SECURE PIPELINE!","text":"<p>Instead of only building the application, we DevSecOps integrates security through the workflow. Such vulnerabilities could be hardcoded passwords, connection strings (secrets). This is a leaky asset, and you never know where it ends up.</p>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#secret-scanning-with-gitleaks","title":"Secret scanning with Gitleaks","text":"<p>Lightweight open-source application for git repositories that detects over 160 secret types, new types added all the time.</p> <p>Running this command inside the git repository, will mount the \".\" local path with /path inside the docker and allow us to scan for all vulnerabilities.</p> <p>In addition add <code>--verbose</code> flag at the end to see on screen what are the encountered vulnerabilites.</p> <pre><code>docker run -v .:/path zricethezav/gitleaks:latest detect --source=\"/path\" #--verbose to see vulnearbilities on screen\n\n\n    \u25cb\n    \u2502\u2572\n    \u2502 \u25cb\n    \u25cb \u2591\n    \u2591    gitleaks\n\n7:11PM INF 132 commits scanned.\n7:11PM INF scanned ~9214215 bytes (9.21 MB) in 1.93s\n7:11PM WRN leaks found: 42\n</code></pre>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#pre-commit-hook-for-secret-scanning","title":"Pre-Commit hook for secret scanning","text":"<p>We can add <code>hooks</code> such as pre-commits which are actions that gets executed before a push is made to remote. These hooks are stored on <code>.git/hooks/pre-commits</code> </p> <p>Note</p> <p>It can be easily be automated with pre-commit which is a python package.</p>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#false-positives","title":"False Positives","text":"<p>First, we cannot block the pipeline deployment with tools that we are not yet sure on how they may behave. This is why we need to allow builds to continue. This can be achieved with pipeline flags such as:</p> <pre><code>gitleaks:\n  stage: test\n  image:\n    name: zricethezav/gitleaks:latest\n    entrypoint: [\"\"]\n  script:\n    - gitleaks detect --verbose --source .\n  allow_failure: true # &lt;- This allows the task to fail but continue!\n</code></pre>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#pipeline-variables","title":"Pipeline Variables","text":"<p>On the Gitlab Project you can head to <code>juice-shop &gt; CI/CD Settings &gt; Variables &gt; Add variable &gt; Key: DOCKER_PASS; Value: my_pass</code>. </p> <p>Note</p> <p>Only DevOps or repository Admins/Owners (1 or 2 team members) should have access to the repository settings to add or modify variables.</p> <pre><code>...\n  variables:\n   DOCKER_USER: onisimiacob\n   DOCKER_PASS: 1234567890! # BAD PRACTICE!!!\n...\n</code></pre> <p>Warning</p> <p>We should CHANGE THE PASSWORD as we already gitted the password. Gitleaks searches all commits, so we need to recreate a new password to fully fix the issue.</p> <pre><code>...\n  variables:\n   DOCKER_USER: $DOCKER_USER\n   DOCKER_PASS: $DOCKER_PASS # GOOD PRACTICE :)\n...\n</code></pre>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#sast-example-tools","title":"SAST Example Tools","text":"<p>Static analysis Security Testing (SAST) main goal is to reduce security findings over time and so that nothing gets deployed to production.</p> <ul> <li>Write secure code.</li> <li>Configure app and system securely.</li> </ul> <p>We add tools to scan the static code, we have SAST tools based on the programming language. For our exercise, we can use a Njscan tool and another Semgrep tool that allows us to scan the local code (thats why it is called static) for vulnerabilities.</p> <pre><code>...\n# Scan for NodeJS SAST vulnerabilies\nnjsscan:\n  stage: test\n  image: python\n  before_script:\n    - pip3 install --upgrade njsscan\n  script:\n    - njsscan --exit-warning . --sarif -o njsscan.sarif\n  allow_failure: true\n\n# Scan with SemGrep\nsemgrep:\n  stage: test\n  image: semgrep/semgrep\n  variables:\n    SEMGREP_RULES: p/javascript\n  script:\n    - semgrep ci --json --output semgrep.json\n  allow_failure: true\n...\n</code></pre>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/3-application-vulnerability-scanning/#sast-scan-results","title":"SAST Scan Results","text":"<p>However, this will create different type of results such as:</p> <ul> <li>NjsScan: It is pretty usefull and easy to understand!</li> </ul> <p></p> <ul> <li>SemGrep: On the other hand, some tools may detect more vulnerabilites but the output is humanly unreadable... </li> </ul> <p></p>","tags":["Vulnerability","Insecure","Practices","Secrets","Cache","Gitleaks","Pre-Commits"]},{"location":"pages/4-vulnerability.management-and-remediation/","title":"\ud83d\udc68\u200d\ud83d\udd27 Vulnerability Management and Remediation","text":"<p>Reports from different tools may be very hard to be orchestrated, and here is where Management tools like DefectDojo come in handy.</p>"},{"location":"pages/4-vulnerability.management-and-remediation/#sast-export-results","title":"SAST Export Results","text":"<p>Most SAST tools allow to export the results as reports. For this example, we added output attributes aswell as artifact funtionality to upload these results to the pipeline build.</p> <pre><code># Scan for Git Leaked credentials\ngitleaks:\n  stage: test\n  image:\n    name: zricethezav/gitleaks:latest\n    entrypoint: [\"\"]\n  script:\n    - gitleaks detect --verbose --source . -f json -r gitleaks.json #(1)\n  allow_failure: true\n  artifacts: \n    when: always\n    paths:\n      - gitleaks.json #(2)\n\n# Scan for NodeJS SAST vulnerabilies\nnjsscan:\n  stage: test\n  image: python\n  before_script:\n    - pip3 install --upgrade njsscan\n  script:\n    - njsscan --exit-warning . --sarif -o njsscan.sarif #(3)\n  allow_failure: true\n  artifacts: \n    when: always\n    paths:\n      - njsscan.sarif #(4)\n\n# Scan with SemGrep\nsemgrep:\n  stage: test\n  image: semgrep/semgrep\n  variables:\n    SEMGREP_RULES: p/javascript\n  script:\n    - semgrep ci --json --output semgrep.json #(5)\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - semgrep.json #(6)\n</code></pre> <ol> <li><code>-f json -r gitleaks.json</code> exports the file as <code>json</code> and as <code>gitleaks.json</code>.</li> <li>This artifact block will upload the <code>gitleaks.json</code> file on the current build always (even if task fails).</li> <li><code>--sarif -o njsscan.sarif</code> exports the file as <code>sarif</code> and as <code>njsscan.sarif</code>.</li> <li>This artifact block will upload the <code>njsscan.sarif</code> file on the current build always (even if task fails).</li> <li><code>--json --output semgrep.json</code> exports the file as <code>json</code> and as <code>semgrep.json</code>.</li> <li>This artifact block will upload the <code>semgrep.json</code> file on the current build always (even if task fails).</li> </ol>"},{"location":"pages/4-vulnerability.management-and-remediation/#defectdojo","title":"DefectDojo","text":"<p>We will use this tool to deploy it locally in order to understand how it works. Nana on the course used the Demo site, however, I wanted to try the Docker-compose version.</p> <ul> <li>Deploy DefectDojo locally.</li> </ul> <pre><code># \ud83d\udc68\u200d\ud83d\udd27 Vulnerability Management and Remediation\n\nReports from different tools may be very hard to be orchestrated, and here is where Management tools like [DefectDojo](https://defectdojo.com/) come in handy.\n\n## SAST Export Results\n\nMost SAST tools allow to export the results as reports. For this example, we added output attributes aswell as artifact funtionality to upload these results to the pipeline build.\n\n```yaml\n# Scan for Git Leaked credentials\ngitleaks:\n  stage: test\n  image:\n    name: zricethezav/gitleaks:latest\n    entrypoint: [\"\"]\n  script:\n    - gitleaks detect --verbose --source . -f json -r gitleaks.json #(1)\n  allow_failure: true\n  artifacts: \n    when: always\n    paths:\n      - gitleaks.json #(2)\n\n# Scan for NodeJS SAST vulnerabilies\nnjsscan:\n  stage: test\n  image: python\n  before_script:\n    - pip3 install --upgrade njsscan\n  script:\n    - njsscan --exit-warning . --sarif -o njsscan.sarif #(3)\n  allow_failure: true\n  artifacts: \n    when: always\n    paths:\n      - njsscan.sarif #(4)\n\n# Scan with SemGrep\nsemgrep:\n  stage: test\n  image: semgrep/semgrep\n  variables:\n    SEMGREP_RULES: p/javascript\n  script:\n    - semgrep ci --json --output semgrep.json #(5)\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - semgrep.json #(6)\n</code></pre> <ol> <li><code>-f json -r gitleaks.json</code> exports the file as <code>json</code> and as <code>gitleaks.json</code>.</li> <li>This artifact block will upload the <code>gitleaks.json</code> file on the current build always (even if task fails).</li> <li><code>--sarif -o njsscan.sarif</code> exports the file as <code>sarif</code> and as <code>njsscan.sarif</code>.</li> <li>This artifact block will upload the <code>njsscan.sarif</code> file on the current build always (even if task fails).</li> <li><code>--json --output semgrep.json</code> exports the file as <code>json</code> and as <code>semgrep.json</code>.</li> <li>This artifact block will upload the <code>semgrep.json</code> file on the current build always (even if task fails).</li> </ol>"},{"location":"pages/4-vulnerability.management-and-remediation/#defectdojo_1","title":"DefectDojo","text":"<p>We will use this tool to deploy it locally in order to understand how it works. Nana on the course used the Demo site, however, I wanted to try the Docker-compose version instead of the ephimeral DefectDojo Demo site.</p> <ul> <li>Deploy DefectDojo locally.</li> </ul> <pre><code># Clone the project\ngit clone https://github.com/DefectDojo/django-DefectDojo\ncd django-DefectDojo\n\n# Check if your installed toolkit is compatible\n./docker/docker-compose-check.sh\n\n# Building Docker images\ndocker compose build\n\n# Run the application (for other profiles besides postgres-redis see  \n# https://github.com/DefectDojo/django-DefectDojo/blob/dev/readme-docs/DOCKER.md)\ndocker compose up -d\n\n# Obtain admin credentials. The initializer can take up to 3 minutes to run.\n# Use docker compose logs -f initializer to track its progress.\ndocker compose logs initializer | grep \"Admin password:\"\n</code></pre>"},{"location":"pages/4-vulnerability.management-and-remediation/#upload-reports-to-defectdojo","title":"Upload Reports to DefectDojo","text":"<p>We will upload reports automatically to DefectDojo form the pipeline.</p> <ul> <li>Head to DefectDojo page and get the API Key: <code>DefectDojo page &gt; User Profile &gt; API v2 Key</code> and copy the key. For example <code>7e494885053ffdeb621d02909201581581872bc4</code>.</li> </ul> <pre><code>import requests\nimport sys\nimport os\n\napi_key = os.environ[\"DEFECTDOJO_API_KEY\"]\nfile_name = sys.argv[1]\nscan_type = '' \n\nif file_name == 'gitleaks.json':\n    scan_type = 'Gitleaks Scan'\nelif file_name == 'njsscan.sarif':\n    scan_type = 'SARIF'\nelif file_name == 'semgrep.json':\n    scan_type = 'Semgrep JSON Report'\nelif file_name == 'retire.json':\n    scan_type = 'Retire.js Scan'\n\nheaders = {\n  'Authorization': f'Token {api_key}'\n\n}\n\nurl = 'http://95.17.91.21:8080/api/v2/import-scan/'\n\ndata = {\n    'auto_create_context': True,\n    'active': True, # it will mark the findings as active\n    'verified': True, # mark as findings as verified automatically\n    'scan_type': scan_type, # this is the type of scan we specified earlyer manually\n    'minimum_severity': 'Low', # results with \"info\" severity won't be imported\n    'product_name': 'Juice Shop',\n    'engagement': 5\n}\n\nfiles = {\n    'file': open(file_name, 'rb')\n}\n\nresponse = requests.post(url, headers=headers, data=data, files=files)\n\n\nif response.status_code == 201:\n    print('Scan results imported successfully')\nelse:\n    print(f'Failed to import scan results: Status_Code: { response.status_code} - Response: {response.content}')\n</code></pre> <p>However, this is how the complete CICD pipeline looks like. I also added the \"DEFECTDOJO_API_KEY\" as a variable to the code, to avoid hardcoding any secret value.</p> <pre><code>variables:\n  IMAGE_NAME: onisimiacob/demo-app\n  IMAGE_VERSION: juice-shop-1.0\n\nstages:\n  - cache\n  - test\n  - build\n\n# Improove build times with a cache task that saves the dependencies as an artifact\ncreate_cache:\n  image: node:18-bullseye\n  stage: cache\n  script:\n    - yarn install --ignore-engines \n  cache:\n    key:\n      files:\n        - yarn.lock\n    paths:\n      - node_modules\n      - yarn.lock\n      - .yarn\n    policy: pull-push\n\n# Test using the cache to speedup testing\nyarn_test:\n  image: node:18-bullseye\n  stage: test\n  script:\n    - yarn install --ignore-engines # fix The engine \"node\" is incompatible with this module. Expected version \"20 || &gt;=22\". Got \"18.20.8\"\n    - yarn test\n  cache:\n    key:\n      files:\n        - yarn.lock\n    paths:\n      - node_modules\n      - yarn.lock\n      - .yarn\n    policy: pull\n\n# Scan for Git Leaked credentials\ngitleaks:\n  stage: test\n  image:\n    name: zricethezav/gitleaks:latest\n    entrypoint: [\"\"]\n  script:\n    - gitleaks detect --verbose --source . -f json -r gitleaks.json\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - gitleaks.json\n\n# Scan for NodeJS SAST vulnerabilies\nnjsscan:\n  stage: test\n  image: python\n  before_script:\n    - pip3 install --upgrade njsscan\n  script:\n    - njsscan --exit-warning . --sarif -o njsscan.sarif\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - njsscan.sarif\n\n# Scan with SemGrep\nsemgrep:\n  stage: test\n  image: semgrep/semgrep\n  variables:\n    SEMGREP_RULES: p/javascript\n  script:\n    - semgrep ci --json --output semgrep.json\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - semgrep.json\n\n# Upload results to DefectDojo\nupload_reports:\n  stage: test\n  image: python\n  needs: [\"gitleaks\", \"njsscan\", \"semgrep\"]\n  when: always\n  variables:\n    DEFECTDOJO_API_KEY: $DEFECTDOJO_API_KEY\n  before_script:\n    - pip3 install requests\n  script:\n    - python3 upload-reports.py gitleaks.json\n    - python3 upload-reports.py njsscan.sarif\n    - python3 upload-reports.py semgrep.json\n\n# Build the docker image\nbuild_image:\n  stage: build\n  image: docker:24\n  services:\n    - docker:24-dind\n  variables:\n    DOCKER_USER: $DOCKER_USER\n    DOCKER_PASS: $DOCKER_PASS\n  before_script:\n    - echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin\n  script:\n    - docker build -t $IMAGE_NAME:$IMAGE_VERSION .\n    - docker push $IMAGE_NAME:$IMAGE_VERSION\n</code></pre> <p></p> <p>This is how DefectDojo looks after pipeline gets executed and scans got imported.</p> <p></p>"},{"location":"pages/5-vulnerability-scanning-for-application-dependencies/","title":"\ud83d\udd17 Vulnerability Scanning for Application Dependencies","text":""},{"location":"pages/5-vulnerability-scanning-for-application-dependencies/#code-from-depencies","title":"Code from Depencies","text":"<p>Our app has thirdparty code (it is not ours). The question is: How do we know if a well known library has any vulnerabilities?</p> <p>We don't! We also need to scan for vulnerability. We cannot do SAST here (Static Composition Software Analysis), we must run SCA (Software Composition Analysis).</p> <ul> <li>SAST - Scan your code for vulerabilities</li> <li>SCA - Scan for vulnerabilities in your dependencies</li> </ul>"},{"location":"pages/5-vulnerability-scanning-for-application-dependencies/#how-can-we-know-if-a-library-has-vulnerabilities","title":"How can we know if a library has vulnerabilities?","text":"<p>Often, these libraries which can be of any language (JavaScript, Java, Python, PHP, Ruby libraries) have this information on Public CVE Databases (Common Vulnerabilities and Exposures), which may include:</p> <ul> <li>What is the issues?</li> <li>Which version is affected?</li> <li>In which version it gets fixed and/or a workaround.</li> </ul>"},{"location":"pages/5-vulnerability-scanning-for-application-dependencies/#add-a-sca-scan-in-pipeline","title":"Add a SCA scan in Pipeline","text":"<p>In previous chapted \ud83d\udc68\u200d\ud83d\udd27 Vulnerability Management and Remediation we created a pipeline and script to upload results to the DefectDojo.</p> <p>SCA vulnerabilities scans are mostly fixed on new verions of the library, however, it may be a dependency of the thirdparty library we require, so it will require some tests in order to ensure that this new upgrade will not break anything.</p> <p>This has to be done hand-in-hand with developers and/or QA team (alternatively launch a End-to-End testing for the app).</p>"},{"location":"pages/6-build-a-cd-pipeline/","title":"\ud83c\udfd7\ufe0f Build a CD Pipeline","text":""},{"location":"pages/6-build-a-cd-pipeline/#introduction","title":"Introduction","text":"<p>The first step is creating an AWS Account (I already have one due to the DevOps Bootcamp). </p>"},{"location":"pages/6-build-a-cd-pipeline/#aws-pre-requisites","title":"AWS Pre-requisites","text":"<ul> <li>After logged in the AWS account, we first need to crete a Amazon Elastic Registry.</li> </ul> <ul> <li>After that, we will create some Access Keys. Nana shows how we can create AWS Access Keys on root account which is a critical.</li> </ul> <ul> <li>Add these Access Keys just like the rest of the variables inside the Juice Shop repository, aswell as the Region and the Account ID.</li> </ul> <ul> <li>We can add this to our CICD pipeline we need to tweak the Build stage.</li> </ul> <pre><code># Build the docker image\nbuild_image:\n  stage: build\n  image: docker:24\n  services:\n    - docker:24-dind\n  before_script:\n    - apk add --no-cache aws-cli\n    - aws ecr get-login-password --region \"$AWS_DEFAULT_REGION\" \\\n        | docker login --username AWS --password-stdin \"$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com\"\n  script:\n    - docker build -t \"$IMAGE_NAME:$CI_COMMIT_SHA\" -t \"$IMAGE_NAME:latest\" .\n    - docker push \"$IMAGE_NAME:$CI_COMMIT_SHA\"\n    - docker push \"$IMAGE_NAME:latest\"\n</code></pre>"},{"location":"pages/6-build-a-cd-pipeline/#complete-cicd-pipeline","title":"Complete CICD Pipeline","text":"<p>Follow this guide to create a EC2 instance: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html </p> <p>Note</p> <p>The creation of the EC2 Instance is a topic that has already been descussed on the previous DevOps bootcamp. </p> <ul> <li> <p>After having the EC2 instance, create a variable on the <code>Git Repository / Settings / CI/CD</code> with the Private SSH Key named <code>SSH_PRIVATE_KEY</code>. </p> </li> <li> <p>This is the complete CICD pipeline:</p> </li> </ul> <pre><code>stages: \n  - cache\n  - test\n  - build\n  - deploy\n\n# Improve build times with a cache task that saves the dependencies as an artifact\ncreate_cache:\n  image: node:18-bullseye\n  stage: cache\n  script:\n    - yarn install --ignore-engines \n  cache:\n    key:\n      files:\n        - yarn.lock\n    paths:\n      - node_modules\n      - yarn.lock\n      - .yarn\n    policy: pull-push\n\n# Test using the cache to speedup testing\nyarn_test:\n  image: node:18-bullseye\n  stage: test\n  script:\n    - yarn install --ignore-engines # fix The engine \"node\" is incompatible with this module. Expected version \"20 || &gt;=22\". Got \"18.20.8\"\n    - yarn test\n  cache:\n    key:\n      files:\n        - yarn.lock\n    paths:\n      - node_modules\n      - yarn.lock\n      - .yarn\n    policy: pull\n\n# Scan for Git Leaked credentials\ngitleaks:\n  stage: test\n  image:\n    name: zricethezav/gitleaks:latest\n    entrypoint: [\"\"]\n  script:\n    - gitleaks detect --verbose --source . -f json -r gitleaks.json\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - gitleaks.json\n\n# Scan for NodeJS SAST vulnerabilies\nnjsscan:\n  stage: test\n  image: python:3.13\n  before_script:\n    - pip3 install --upgrade njsscan\n  script:\n    - njsscan --exit-warning . --sarif -o njsscan.sarif\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - njsscan.sarif\n\n# Scan with SemGrep\nsemgrep:\n  stage: test\n  image: semgrep/semgrep\n  variables:\n    SEMGREP_RULES: p/javascript\n  script:\n    - semgrep ci --json --output semgrep.json\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - semgrep.json\n\nretire:\n  stage: test\n  image: node:18-bullseye\n  cache:\n    key:\n      files:\n        - yarn.lock\n    paths:\n      - node_modules\n      - yarn.lock\n      - .yarn\n    policy: pull\n  before_script:\n    - npm install -g retire\n  script:\n    - retire --path . --outputformat json --outputpath retire.json\n  allow_failure: true\n  artifacts:\n    when: always\n    paths:\n      - retire.json\n\n# Upload results to DefectDojo\nupload_reports:\n  stage: test\n  image: python\n  needs: [\"gitleaks\", \"njsscan\", \"semgrep\", \"retire\"]\n  when: always\n  variables:\n    DEFECTDOJO_API_KEY: $DEFECTDOJO_API_KEY\n  before_script:\n    - pip3 install requests\n  script:\n    - python3 upload-reports.py gitleaks.json\n    - python3 upload-reports.py njsscan.sarif\n    - python3 upload-reports.py semgrep.json\n    - python3 upload-reports.py retire.json\n\n# Build the docker image\nbuild_image:\n  stage: build\n  image: docker:24\n  variables:\n    IMAGE_NAME: $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/juice-shop\n  services:\n    - docker:24-dind\n  before_script:\n    - apk add --no-cache aws-cli\n    - aws ecr get-login-password --region $AWS_DEFAULT_REGION |\n      docker login --username AWS --password-stdin ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com\n\n  script:\n    - docker build -t \"$IMAGE_NAME:$CI_COMMIT_SHA\" -t \"$IMAGE_NAME:latest\" .\n    - docker push \"$IMAGE_NAME:$CI_COMMIT_SHA\"\n    - docker push \"$IMAGE_NAME:latest\"\n\n# Deploy the container to the EC2 instance through SSH (not for production workloads)\ndeploy_image:\n  stage: deploy\n  image: debian:bullseye-slim\n  before_script:\n    - apt update -y &amp;&amp; apt install openssh-client -y\n    - eval $(ssh-agent -s)\n    - chmod 400 \"$SSH_PRIVATE_KEY\"\n    - ssh-add \"$SSH_PRIVATE_KEY\"\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n  script:\n    - ssh -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_IP \"docker pull $IMAGE_NAME:latest\"\n    - ssh -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_IP \"docker stop juice-shop || true &amp;&amp; docker rm juice-shop || true\"\n    - ssh -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_IP \"docker run -d --name juice-shop -p 3000:3000 $IMAGE_NAME:latest\"\n</code></pre>"},{"location":"pages/6-build-a-cd-pipeline/#self-managed-gitlab-runners","title":"Self-Managed Gitlab Runners","text":"<ul> <li> <p>Follow Gitlab Runner Install Guide Amazon Linux and how to install Docker Install Guide Amazon Linux.</p> </li> <li> <p>Head to Gitlab Runners and click <code>Create project runner</code>.</p> </li> </ul> <p></p> <ul> <li>Set a Name and set it up only for this project.</li> </ul> <p></p> <ul> <li>Copy the command with the token.</li> </ul> <p></p> <ul> <li>For this we used a <code>Amazon Linux</code> with <code>t3.large</code> as instance, <code>30GB of gp3</code> disk and <code>ssh 22 port open</code>. These are the commands executed on the server:</li> </ul> <pre><code># update package repos\nsudo yum update\n\n# Download script gitLab runner\ncurl -L \"https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh\" -o script.rpm.sh\n\n# Install gitlab runner on Amazon Linux\nsudo bash script.rpm.sh\n\n# Now update to the latest version\nsudo yum update\nsudo yum install gitlab-runner\n\n# Install docker on Amazon Linux\nsudo yum install -y docker\n\n# Start Docker Service\nsudo service docker start\n\n# Add gitlab-runner &amp; ec2 users to docker group\nsudo usermod -aG docker gitlab-runner\nsudo usermod -aG docker ec2-user\n\n# Register runner\nsudo gitlab-runner register \\\n--url \"https://gitlab.com/\" \\\n--token \"glrt-XXXXX\" \\\n--executor \"shell\"\n\n# Start runner\ngitlab-runner run\n</code></pre> <ul> <li>This is the validation of the runner being online.</li> </ul> <p></p> <ul> <li>Using the Self-Hosted Runner requires to remove the \"docker-in-docker\" image from the pipeline</li> </ul> <p></p> <ul> <li>Validate docker build on the runner via ssh.</li> </ul> <p></p>"},{"location":"pages/7-image-scanning-build-secure-docker-images/","title":"\ud83d\udc0b Image Scanning - Build Secure Docker Images","text":""},{"location":"pages/7-image-scanning-build-secure-docker-images/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/8-aws-cloud-security-and-access-management/","title":"\ud83d\udfe0 AWS Cloud Security &amp; Access Management","text":""},{"location":"pages/8-aws-cloud-security-and-access-management/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""},{"location":"pages/9-secure-continuous-deployment-and-dast/","title":"\ud83d\udd10 Secure Continuous Deployment &amp; DAST","text":""},{"location":"pages/9-secure-continuous-deployment-and-dast/#work-in-progress","title":"\ud83d\udea7 WORK IN PROGRESS...","text":""}]}